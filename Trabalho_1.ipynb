{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHO6AESuxnGM"
      },
      "source": [
        "# Trabalho 1 - Nivelamento\n",
        "\n",
        "Considere os datasets abaixo, estratégias de pré-processamento, medidas de avaliação, métodos de comparação estatística e os seguintes algoritmos de aprendizado de máquina: árvore de decisão, random forest e k-nearest neighbor. A partir disso, responda as seguintes perguntas:\n",
        "\n",
        "1. Qual o algoritmo de AM mais adequado para cada problema?\n",
        "2. Qual o algoritmo de AM mais adequado para todos os problemas?\n",
        "knn:85.94066985255232\n",
        "Arvore de decisão:85.42638695604664\n",
        "Random Florest:86.62282691074151\n",
        "Partindo de uma comparação direta entre os resultados do cross validation usando o msm conjunto de dados para todos, o algoritmo de random florest é o melhor, no entanto é o mais demorado também demorando 31 minutos para processar tudo, enquanto so demais demoraram apenas 1 minuto cada, em segundo fica o knn e terceiro a arvore de decisão que tem tempos similares. As únicas alterações feitas no dataset foi a seleção de atributos, e a conversão de atributos nominais para numéricos/binários utilizando o getdummies ou a conversão direta para os que tinham apenas duas classes.\n",
        "\n",
        "Para responder essas questões construa um notebook no colab ou um ambiente similar. Documente de forma clara cada passo e justifique suas decisões."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "LOdk7BJHxmH4"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_selection import RFE\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib as plt\n",
        "from scipy.io import arff\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Link com os datasets'''\n",
        "PhishingWebsites_link = \"https://www.openml.org/data/download/1798106/phpV5QYya\"\n",
        "arrhythmia_link       = \"https://www.openml.org/data/download/53551/arrhythmia.arff\"\n",
        "Satellite_link        = \"https://www.openml.org/data/download/16787463/phpZrCzJR\"\n",
        "airlines_link         = \"https://www.openml.org/data/download/66526/phpvcoG8S\"\n",
        "AedesSex_link         = \"https://github.com/denismr/Classification-and-Counting-with-Recurrent-Contexts/raw/master/codeAndData/data/AedesSex.csv\"\n",
        "phoneme_link          = \"https://www.openml.org/data/download/1592281/php8Mz7BG\"\n",
        "adult_link            = \"https://www.openml.org/data/download/1595261/phpMawTba\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loadDataset_Arff(url: str) -> pd.DataFrame:\n",
        "  '''Função responsável por ler os datasets do tipo .arff'''\n",
        "  ftpstream = urllib.request.urlopen(url)\n",
        "  return pd.DataFrame(arff.loadarff(io.StringIO(ftpstream.read().decode('utf-8')))[0])\n",
        "  \n",
        "def get_dummies(df: pd.DataFrame, col:str) -> pd.DataFrame:\n",
        "  '''Função responsável por separar os dados nominais em outras colunas.'''\n",
        "  return pd.get_dummies(df,prefix=col,prefix_sep='.',columns=[col]).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def proportion(Dataset,target=\"Target\"):\n",
        "  '''Função que gera um gráfico de proporção dos valores targets'''\n",
        "  target_count = Dataset[target].value_counts()\n",
        "  print('Class 0:', target_count[0])\n",
        "  print('Class 1:', target_count[1])\n",
        "  target_count.plot(kind='bar', title='Count (target)');\n",
        "  \n",
        "def normalize(dataset,target='Target') -> pd.DataFrame:\n",
        "  '''Função que retorna o dataset normalizado'''\n",
        "  X = dataset.drop([target], axis=1).copy()\n",
        "  Y = dataset[target].copy()\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "  dataset = X\n",
        "  dataset[target] = Y\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def knn(dataset,n_neighbors=3,target='Target'):\n",
        "  '''Função que aplica o knn'''\n",
        "  X_train, X_test, y_train, y_test = train_test_split(dataset.drop([target], axis=1), dataset[target], test_size=0.3)\n",
        "  model = KNeighborsClassifier(n_neighbors=3)\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(accuracy_score(y_test, y_pred)*100)\n",
        "\n",
        "def treeDecision(dataset,target='Target'):\n",
        "  '''Função que aplica a arvore de decisão'''\n",
        "  X_train, X_test, y_train, y_test = train_test_split(dataset.drop([target], axis=1), dataset[target], test_size=0.3)\n",
        "  model = DecisionTreeClassifier()\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(accuracy_score(y_test, y_pred)*100)\n",
        "\n",
        "def RForestDecision(dataset,target='Target'):\n",
        "  '''Função que aplica random florest'''\n",
        "  X_train, X_test, y_train, y_test = train_test_split(dataset.drop([target], axis=1), dataset[target], test_size=0.3)\n",
        "  model = RandomForestClassifier()\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(accuracy_score(y_test, y_pred)*100)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def TTS_knn(dataset, x ,y ,n_neighbors=3):\n",
        "  '''Função que aplica o knn com x e y previamente setados'''\n",
        "  model = KNeighborsClassifier(n_neighbors=3)\n",
        "  return cross_val_score(model, x, y, cv=20, scoring=\"accuracy\")\n",
        "\n",
        "def TTS_treeDecision(dataset, x ,y):\n",
        "  '''Função que aplica a arvore de decisão com x e y previamente setados'''\n",
        "  model = DecisionTreeClassifier()\n",
        "  return cross_val_score(model, x, y, cv=20, scoring=\"accuracy\")\n",
        "\n",
        "def TTS_RForestDecision(dataset, x ,y):\n",
        "  '''Função que aplica o random florest com x e y previamente setados'''\n",
        "  model = RandomForestClassifier()\n",
        "  return cross_val_score(model, x, y, cv=20, scoring=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def selectAttributes(dataset):\n",
        "  '''Função que aplica o knn com x e y previamente setados'''\n",
        "  model = DecisionTreeClassifier()#max_leaf_nodes=10\n",
        "  feature_ = RFE(model,n_features_to_select=5, step=1)\n",
        "  return feature_.fit(dataset.drop(['Target'],axis=1),dataset['Target']).support_\n",
        "\n",
        "def removeColumns(dataset):\n",
        "  '''Função que faz a seleção de atributos e retorna uma lista com o nome das colunas que serão removidas'''\n",
        "  attributes = selectAttributes(dataset)\n",
        "  dropListIndex = np.where(attributes == False)[0]\n",
        "  dropList = []\n",
        "  for index in dropListIndex:\n",
        "    if(dataset.columns[index] != \"Target\"):\n",
        "      dropList.append(dataset.columns[index])\n",
        "  return dropList\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def underSampling(dataset):\n",
        "  # CONTAR CLASSES\n",
        "  count_class_1, count_class_0 = dataset.Target.value_counts()\n",
        "  # # Divide by class\n",
        "  df_class_0 = dataset[dataset['Target'] == 0]\n",
        "  df_class_1 = dataset[dataset['Target'] == 1]\n",
        "  df_class_1_under = df_class_1.sample(int(count_class_1*0.8))\n",
        "  df_test_under = pd.concat([df_class_1_under, df_class_0], axis=0)\n",
        "  return df_test_under\n",
        "\n",
        "def overSampling(dataset):\n",
        "  # CONTAR CLASSES\n",
        "  count_class_1, count_class_0 = dataset.Target.value_counts()\n",
        "  print(count_class_1, count_class_0)\n",
        "  # # Divide by class\n",
        "  df_class_0 = dataset[dataset['Target'] == 0]\n",
        "  df_class_1 = dataset[dataset['Target'] == 1]\n",
        "  df_class_0_over = df_class_0.sample(int(count_class_0/0.85),replace=True)\n",
        "  df_test_over = pd.concat([df_class_0_over, df_class_1], axis=0)\n",
        "  return df_test_over"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lendo todos os datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "InitDataset_PhishingWebsites = loadDataset_Arff(PhishingWebsites_link)\n",
        "InitDataset_arrhythmia = loadDataset_Arff(arrhythmia_link)\n",
        "InitDataset_Satellite = loadDataset_Arff(Satellite_link)\n",
        "InitDataset_airlines = loadDataset_Arff(airlines_link)\n",
        "InitDataset_AedesSex = pd.read_csv(AedesSex_link)\n",
        "InitDataset_phoneme = loadDataset_Arff(phoneme_link)\n",
        "InitDataset_adult = loadDataset_Arff(adult_link)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Abaixo será feito a conversão das classes targets para True e False, e trocado o nome da coluna para Target para as que não estão. Também será feito uma analise de distribuição e procura de dados nominais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "Dataset_PhishingWebsites = InitDataset_PhishingWebsites.copy()\n",
        "Dataset_PhishingWebsites['Target'] = [True if x == '-1'.encode() else False for x in Dataset_PhishingWebsites['Result']]\n",
        "Dataset_PhishingWebsites = Dataset_PhishingWebsites.drop(['Result'],axis=1)\n",
        "Dataset_PhishingWebsites = Dataset_PhishingWebsites.drop(removeColumns(Dataset_PhishingWebsites),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "Dataset_arrhythmia = InitDataset_arrhythmia.copy()\n",
        "Dataset_arrhythmia['Target'] = [True if x == 'P'.encode() else False for x in Dataset_arrhythmia['binaryClass']]\n",
        "Dataset_arrhythmia = Dataset_arrhythmia.drop(['binaryClass'],axis=1) #Remoção da coluna J por ter 98% dos dados NaN\n",
        "Dataset_arrhythmia = Dataset_arrhythmia.dropna() #Remoção das linhas com valores faltantes\n",
        "Dataset_arrhythmia = Dataset_arrhythmia.drop(removeColumns(Dataset_arrhythmia),axis=1) \n",
        "Dataset_arrhythmia.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "##Sem nominais usando a função select_nominals\n",
        "Dataset_Satellite = InitDataset_Satellite.copy()\n",
        "Dataset_Satellite['Target'] = [True if x == 'Anomaly'.encode() else False for x in Dataset_Satellite['Target']]\n",
        "Dataset_Satellite = Dataset_Satellite.drop(removeColumns(Dataset_Satellite),axis=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "##Dataset com muitos dados nominais, para aplicar o knn será necessário usar a função getdummies em AirportFrom e AirportTo.\n",
        "Dataset_airlines = InitDataset_airlines.copy()\n",
        "Dataset_airlines['Target'] = [True if x == '1'.encode() else False for x in Dataset_airlines['Delay']]\n",
        "Dataset_airlines = Dataset_airlines.drop(['Delay'],axis=1)\n",
        "\n",
        "Dataset_airlines = Dataset_airlines.drop_duplicates()\n",
        "\n",
        "\n",
        "Dataset_airlines['Airline'] = Dataset_airlines['Airline'].astype('category')\n",
        "Dataset_airlines['AirportFrom'] = Dataset_airlines['AirportFrom'].astype('category')\n",
        "Dataset_airlines['AirportTo'] = Dataset_airlines['AirportTo'].astype('category')\n",
        "\n",
        "Dataset_airlines['Airline'] = Dataset_airlines['Airline'].cat.codes\n",
        "Dataset_airlines['AirportFrom'] = Dataset_airlines['AirportFrom'].cat.codes\n",
        "Dataset_airlines['AirportTo'] = Dataset_airlines['AirportTo'].cat.codes\n",
        "\n",
        "Dataset_airlines = Dataset_airlines.drop(removeColumns(Dataset_airlines),axis=1)\n",
        "Dataset_airlines.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "Dataset_AedesSex = InitDataset_AedesSex.copy()\n",
        "Dataset_AedesSex['Target'] = [True if x == 'F' else False for x in Dataset_AedesSex['sex']]\n",
        "Dataset_AedesSex = Dataset_AedesSex.drop(['sex'],axis=1)\n",
        "Dataset_AedesSex = Dataset_AedesSex.drop(removeColumns(Dataset_AedesSex),axis=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3054 1586\n"
          ]
        }
      ],
      "source": [
        "Dataset_phoneme = InitDataset_phoneme.copy()\n",
        "Dataset_phoneme['Target'] = [True if x == '1'.encode() else False for x in Dataset_phoneme['Class']]\n",
        "Dataset_phoneme = Dataset_phoneme.drop(['Class'],axis=1)\n",
        "Dataset_phoneme = Dataset_phoneme.drop(removeColumns(Dataset_phoneme),axis=1)\n",
        "Dataset_phoneme = overSampling(underSampling(Dataset_phoneme))#Aplicando over e undersampling para 15% dos dados para tentar deixar mais proporcional o dataset\n",
        "Dataset_phoneme.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "Dataset_adult = InitDataset_adult.copy()\n",
        "Dataset_adult['Target'] = [True if x == '<=50K'.encode() else False for x in Dataset_adult['class']]\n",
        "Dataset_adult = Dataset_adult.drop(['class'],axis=1)\n",
        "Dataset_adult['workclass'] = [x.decode('UTF-8') for x in Dataset_adult['workclass']]\n",
        "Dataset_adult['education'] = [x.decode('UTF-8') for x in Dataset_adult['education']]\n",
        "Dataset_adult['marital-status'] = [x.decode('UTF-8') for x in Dataset_adult['marital-status']]\n",
        "Dataset_adult['occupation'] = [x.decode('UTF-8') for x in Dataset_adult['occupation']]\n",
        "Dataset_adult['relationship'] = [x.decode('UTF-8') for x in Dataset_adult['relationship']]\n",
        "Dataset_adult['race'] = [x.decode('UTF-8') for x in Dataset_adult['race']]\n",
        "Dataset_adult['sex'] = [x.decode('UTF-8') for x in Dataset_adult['sex']]\n",
        "Dataset_adult['native-country'] = [x.decode('UTF-8') for x in Dataset_adult['native-country']]\n",
        "\n",
        "Dataset_adult = Dataset_adult.dropna() #Remoção das linhas com valores faltantes\n",
        "Dataset_adult = get_dummies(Dataset_adult,'workclass')\n",
        "Dataset_adult = get_dummies(Dataset_adult,'education')\n",
        "Dataset_adult = get_dummies(Dataset_adult,'marital-status')\n",
        "Dataset_adult = get_dummies(Dataset_adult,'occupation')\n",
        "Dataset_adult = get_dummies(Dataset_adult,'relationship')\n",
        "Dataset_adult = get_dummies(Dataset_adult,'race')\n",
        "Dataset_adult = get_dummies(Dataset_adult,'sex')\n",
        "Dataset_adult = get_dummies(Dataset_adult,'native-country')\n",
        "Dataset_adult = Dataset_adult.drop(removeColumns(Dataset_adult),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "##Normalizando todos os dados\n",
        "NOR_Dataset_PhishingWebsites = normalize(Dataset_PhishingWebsites)\n",
        "NOR_Dataset_arrhythmia = normalize(Dataset_arrhythmia)\n",
        "NOR_Dataset_Satellite = normalize(Dataset_Satellite)\n",
        "NOR_Dataset_AedesSex = normalize(Dataset_AedesSex)\n",
        "NOR_Dataset_airlines = normalize(Dataset_airlines)\n",
        "NOR_Dataset_phoneme = normalize(Dataset_phoneme)\n",
        "NOR_Dataset_adult = normalize(Dataset_adult)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# knn(NOR_Dataset_PhishingWebsites) #93.8498643352427\n",
        "knn(NOR_Dataset_arrhythmia) \n",
        "# knn(NOR_Dataset_Satellite) #99.2156862745098\n",
        "# knn(NOR_Dataset_AedesSex) #98.73611111111111\n",
        "# knn(NOR_Dataset_phoneme) #88.03945745992601\n",
        "# knn(NOR_Dataset_adult) #81.71022998703337\n",
        "# knn(NOR_Dataset_airlines) #81.71022998703337\n",
        "\n",
        "\n",
        "# treeDecision(NOR_Dataset_PhishingWebsites)#96.02050045221586\n",
        "# treeDecision(NOR_Dataset_arrhythmia)\n",
        "# treeDecision(NOR_Dataset_Satellite)#99.08496732026144\n",
        "# treeDecision(NOR_Dataset_AedesSex)#98.19444444444444\n",
        "# treeDecision(NOR_Dataset_phoneme)#87.05302096177559\n",
        "# treeDecision(NOR_Dataset_adult)#82.01733433426602\n",
        "# treeDecision(NOR_Dataset_airlines)\n",
        "\n",
        "\n",
        "# RForestDecision(NOR_Dataset_PhishingWebsites)#96.80434127223396\n",
        "# RForestDecision(NOR_Dataset_arrhythmia)\n",
        "# RForestDecision(NOR_Dataset_Satellite)#99.281045751634\n",
        "# RForestDecision(NOR_Dataset_AedesSex)#98.38888888888889\n",
        "# RForestDecision(NOR_Dataset_phoneme)#90.9987669543773\n",
        "# RForestDecision(NOR_Dataset_adult)#85.68893741895857\n",
        "# RForestDecision(NOR_Dataset_airlines)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "##Separando os atributos dos datasets para testar qual o melhor algoritmo\n",
        "NOR_Dataset_PhishingWebsites_y = NOR_Dataset_PhishingWebsites['Target']\n",
        "NOR_Dataset_PhishingWebsites_x = NOR_Dataset_PhishingWebsites.drop(['Target'],axis=1)\n",
        "\n",
        "NOR_Dataset_Satellite_y = NOR_Dataset_Satellite['Target']\n",
        "NOR_Dataset_Satellite_x = NOR_Dataset_Satellite.drop(['Target'],axis=1)\n",
        "\n",
        "NOR_Dataset_AedesSex_y = NOR_Dataset_AedesSex['Target']\n",
        "NOR_Dataset_AedesSex_x = NOR_Dataset_AedesSex.drop(['Target'],axis=1)\n",
        "\n",
        "NOR_Dataset_phoneme_y = NOR_Dataset_phoneme['Target']\n",
        "NOR_Dataset_phoneme_x = NOR_Dataset_phoneme.drop(['Target'],axis=1)\n",
        "\n",
        "NOR_Dataset_adult_y = NOR_Dataset_adult['Target']\n",
        "NOR_Dataset_adult_x = NOR_Dataset_adult.drop(['Target'],axis=1)\n",
        "\n",
        "NOR_Dataset_airlines_y = NOR_Dataset_airlines['Target']\n",
        "NOR_Dataset_airlines_x = NOR_Dataset_airlines.drop(['Target'],axis=1)\n",
        "\n",
        "NOR_Dataset_arrhythmia_y = NOR_Dataset_arrhythmia['Target']\n",
        "NOR_Dataset_arrhythmia_x = NOR_Dataset_arrhythmia.drop(['Target'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "##Calculando a media de todos os datasets a partir do cross validation juntamente com o knn\n",
        "resultCrossValidationKnnDataset_PhishingWebsites = TTS_knn(NOR_Dataset_PhishingWebsites,NOR_Dataset_PhishingWebsites_x,NOR_Dataset_PhishingWebsites_y) \n",
        "resultCrossValidationKnnDataset_Satellite = TTS_knn(NOR_Dataset_Satellite,NOR_Dataset_Satellite_x,NOR_Dataset_Satellite_y) \n",
        "resultCrossValidationKnnDataset_AedesSex = TTS_knn(NOR_Dataset_AedesSex,NOR_Dataset_AedesSex_x,NOR_Dataset_AedesSex_y) \n",
        "resultCrossValidationKnnDataset_phoneme = TTS_knn(NOR_Dataset_phoneme,NOR_Dataset_phoneme_x,NOR_Dataset_phoneme_y) \n",
        "resultCrossValidationKnnDataset_adult = TTS_knn(NOR_Dataset_adult,NOR_Dataset_adult_x,NOR_Dataset_adult_y) \n",
        "resultCrossValidationKnnDataset_airlines = TTS_knn(NOR_Dataset_airlines,NOR_Dataset_airlines_x,NOR_Dataset_airlines_y) \n",
        "resultCrossValidationKnnDataset_arrhythmia = TTS_knn(NOR_Dataset_arrhythmia,NOR_Dataset_arrhythmia_x,NOR_Dataset_arrhythmia_y) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.90596745 0.92766727 0.93490054 0.92585895 0.93851718 0.92947559\n",
            " 0.94575045 0.91139241 0.92766727 0.92947559 0.9403255  0.95298373\n",
            " 0.91681736 0.93670886 0.93128391 0.86050725 0.89492754 0.88768116\n",
            " 0.90036232 0.89492754] [0.99607843 0.99607843 0.99215686 0.98823529 1.         0.99607843\n",
            " 0.99607843 0.99607843 0.99607843 0.99215686 0.99607843 0.99607843\n",
            " 0.98823529 0.98823529 0.99607843 0.99607843 0.99607843 0.98823529\n",
            " 0.99215686 0.99215686] [0.9725     0.93833333 0.98       0.99       0.98083333 0.9825\n",
            " 0.98583333 0.9925     0.99166667 0.9825     0.94666667 0.98083333\n",
            " 0.98833333 0.98833333 0.99       0.9825     0.98666667 0.9875\n",
            " 0.99       0.99416667] [0.90243902 0.89430894 0.90243902 0.91869919 0.90650407 0.87398374\n",
            " 0.87804878 0.86585366 0.91869919 0.89837398 0.90243902 0.89430894\n",
            " 0.90243902 0.89837398 0.88211382 0.91056911 0.87804878 0.91056911\n",
            " 0.84552846 0.88163265] [0.78141629 0.76217765 0.77846028 0.77395577 0.77436527 0.77108927\n",
            " 0.77600328 0.75962326 0.78869779 0.79197379 0.77354627 0.76658477\n",
            " 0.77067977 0.76986077 0.77723178 0.77559378 0.78583129 0.77927928\n",
            " 0.78746929 0.76863227] [0.34853461 0.33880662 0.24604994 0.21575067 0.29363653 0.24885364\n",
            " 0.19432396 0.27314413 0.34837031 0.15175362 0.33523361 0.22921056\n",
            " 0.29191969 0.32308836 0.34328913 0.36268435 0.32438964 0.37173132\n",
            " 0.27450737 0.2658322 ] [0.5        0.75       0.5        0.75       1.         0.75\n",
            " 1.         0.5        0.66666667 0.66666667 0.33333333 0.66666667\n",
            " 1.         1.         0.66666667 0.66666667 0.66666667 0.66666667\n",
            " 0.66666667 0.66666667]\n"
          ]
        }
      ],
      "source": [
        "print(resultCrossValidationKnnDataset_PhishingWebsites,\n",
        "resultCrossValidationKnnDataset_Satellite,\n",
        "resultCrossValidationKnnDataset_AedesSex,\n",
        "resultCrossValidationKnnDataset_phoneme,\n",
        "resultCrossValidationKnnDataset_adult,\n",
        "resultCrossValidationKnnDataset_airlines,\n",
        "resultCrossValidationKnnDataset_arrhythmia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "##Calculando a media de todos os datasets a partir do cross validation juntamente com a árvore de decisão\n",
        "resultCrossValidationTreeDecisionDataset_PhishingWebsites = TTS_treeDecision(NOR_Dataset_PhishingWebsites,NOR_Dataset_PhishingWebsites_x,NOR_Dataset_PhishingWebsites_y) \n",
        "resultCrossValidationTreeDecisionDataset_Satellite = TTS_treeDecision(NOR_Dataset_Satellite,NOR_Dataset_Satellite_x,NOR_Dataset_Satellite_y) \n",
        "resultCrossValidationTreeDecisionDataset_AedesSex = TTS_treeDecision(NOR_Dataset_AedesSex,NOR_Dataset_AedesSex_x,NOR_Dataset_AedesSex_y) \n",
        "resultCrossValidationTreeDecisionDataset_phoneme = TTS_treeDecision(NOR_Dataset_phoneme,NOR_Dataset_phoneme_x,NOR_Dataset_phoneme_y) \n",
        "resultCrossValidationTreeDecisionDataset_adult = TTS_treeDecision(NOR_Dataset_adult,NOR_Dataset_adult_x,NOR_Dataset_adult_y) \n",
        "resultCrossValidationTreeDecisionDataset_airlines = TTS_treeDecision(NOR_Dataset_airlines,NOR_Dataset_airlines_x,NOR_Dataset_airlines_y) \n",
        "resultCrossValidationTreeDecisionDataset_arrhythmia = TTS_treeDecision(NOR_Dataset_arrhythmia,NOR_Dataset_arrhythmia_x,NOR_Dataset_arrhythmia_y) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.90958409 0.93128391 0.91862568 0.92585895 0.93670886 0.90958409\n",
            " 0.93851718 0.91500904 0.90958409 0.93128391 0.93128391 0.94936709\n",
            " 0.920434   0.93490054 0.92947559 0.87137681 0.93297101 0.91485507\n",
            " 0.92934783 0.92934783] [0.99607843 0.99607843 0.99215686 0.98823529 0.98823529 0.98823529\n",
            " 0.99607843 0.99215686 0.97647059 0.98431373 0.99607843 0.99215686\n",
            " 0.99215686 0.99215686 0.99607843 0.99607843 0.99607843 0.98431373\n",
            " 0.98431373 0.98431373] [0.955      0.92583333 0.96416667 0.9775     0.98333333 0.98416667\n",
            " 0.9825     0.9925     0.9925     0.99416667 0.9275     0.97\n",
            " 0.98166667 0.9825     0.99       0.98083333 0.98583333 0.98333333\n",
            " 0.98916667 0.99416667] [0.89430894 0.8902439  0.8902439  0.91056911 0.92682927 0.90243902\n",
            " 0.91056911 0.93902439 0.88617886 0.91056911 0.91869919 0.90243902\n",
            " 0.90243902 0.91463415 0.89837398 0.90650407 0.91056911 0.92276423\n",
            " 0.91056911 0.88571429] [0.75521899 0.76135898 0.75307125 0.76248976 0.74406224 0.75593776\n",
            " 0.76453726 0.75921376 0.75307125 0.76371826 0.75921376 0.74774775\n",
            " 0.75757576 0.75716626 0.75593776 0.74242424 0.76699427 0.75839476\n",
            " 0.76494676 0.74979525] [0.24456286 0.26135448 0.23508272 0.19784373 0.28260735 0.20609741\n",
            " 0.1552237  0.26849672 0.35500062 0.10044615 0.18558681 0.09852522\n",
            " 0.19072995 0.29291114 0.29600942 0.28832569 0.25319123 0.27729582\n",
            " 0.20553972 0.13130499] [0.75       1.         0.75       0.25       1.         0.75\n",
            " 1.         0.5        0.66666667 1.         0.33333333 0.66666667\n",
            " 1.         1.         1.         1.         0.66666667 1.\n",
            " 0.66666667 1.        ]\n"
          ]
        }
      ],
      "source": [
        "print(resultCrossValidationTreeDecisionDataset_PhishingWebsites,\n",
        "resultCrossValidationTreeDecisionDataset_Satellite,\n",
        "resultCrossValidationTreeDecisionDataset_AedesSex,\n",
        "resultCrossValidationTreeDecisionDataset_phoneme,\n",
        "resultCrossValidationTreeDecisionDataset_adult,\n",
        "resultCrossValidationTreeDecisionDataset_airlines,\n",
        "resultCrossValidationTreeDecisionDataset_arrhythmia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "##Calculando a media de todos os datasets a partir do cross validation juntamente com o algoritmo de random florest.\n",
        "resultCrossValidationRFDataset_PhishingWebsites = TTS_RForestDecision(NOR_Dataset_PhishingWebsites,NOR_Dataset_PhishingWebsites_x,NOR_Dataset_PhishingWebsites_y) \n",
        "resultCrossValidationRFDataset_Satellite = TTS_RForestDecision(NOR_Dataset_Satellite,NOR_Dataset_Satellite_x,NOR_Dataset_Satellite_y) \n",
        "resultCrossValidationRFDataset_AedesSex = TTS_RForestDecision(NOR_Dataset_AedesSex,NOR_Dataset_AedesSex_x,NOR_Dataset_AedesSex_y) \n",
        "resultCrossValidationRFDataset_phoneme = TTS_RForestDecision(NOR_Dataset_phoneme,NOR_Dataset_phoneme_x,NOR_Dataset_phoneme_y) \n",
        "resultCrossValidationRFDataset_adult = TTS_RForestDecision(NOR_Dataset_adult,NOR_Dataset_adult_x,NOR_Dataset_adult_y) \n",
        "resultCrossValidationRFDataset_airlines = TTS_RForestDecision(NOR_Dataset_airlines,NOR_Dataset_airlines_x,NOR_Dataset_airlines_y) \n",
        "resultCrossValidationRFDataset_arrhythmia = TTS_RForestDecision(NOR_Dataset_arrhythmia,NOR_Dataset_arrhythmia_x,NOR_Dataset_arrhythmia_y) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.90958409 0.93128391 0.920434   0.92585895 0.93670886 0.90958409\n",
            " 0.93851718 0.91500904 0.92585895 0.93128391 0.93128391 0.94936709\n",
            " 0.920434   0.93490054 0.92947559 0.86594203 0.93297101 0.91666667\n",
            " 0.92572464 0.92934783] [0.99607843 0.99607843 0.99215686 0.98823529 0.99607843 0.99607843\n",
            " 0.99607843 0.99215686 0.99607843 0.98823529 1.         0.99215686\n",
            " 0.98823529 0.99215686 0.99607843 0.99607843 0.99607843 0.99215686\n",
            " 0.99607843 0.99215686] [0.97416667 0.94583333 0.97666667 0.98916667 0.99083333 0.99083333\n",
            " 0.9875     0.995      0.99583333 0.99333333 0.955      0.98083333\n",
            " 0.98666667 0.98916667 0.99083333 0.99083333 0.9875     0.98666667\n",
            " 0.99333333 0.99666667] [0.94308943 0.92682927 0.93089431 0.95121951 0.95934959 0.91869919\n",
            " 0.93495935 0.94308943 0.92276423 0.94308943 0.94308943 0.93902439\n",
            " 0.92682927 0.93495935 0.90650407 0.93495935 0.93902439 0.93089431\n",
            " 0.92682927 0.95102041] [0.77568563 0.76872698 0.77395577 0.77231777 0.77067977 0.78337428\n",
            " 0.77764128 0.77682228 0.78746929 0.77600328 0.76781327 0.76044226\n",
            " 0.77682228 0.77149877 0.78091728 0.77027027 0.79320229 0.77272727\n",
            " 0.78009828 0.76822277] [0.26662123 0.28508582 0.21135138 0.16283537 0.28719252 0.18769364\n",
            " 0.10335853 0.22828108 0.31868881 0.08563639 0.22227042 0.09759574\n",
            " 0.19884744 0.29737266 0.33634899 0.33678275 0.24835791 0.31391746\n",
            " 0.24346263 0.13979427] [0.5        1.         0.75       0.5        0.75       0.75\n",
            " 1.         0.75       0.66666667 0.66666667 0.33333333 0.66666667\n",
            " 1.         1.         1.         1.         0.66666667 0.66666667\n",
            " 0.66666667 1.        ]\n"
          ]
        }
      ],
      "source": [
        "print(resultCrossValidationRFDataset_PhishingWebsites,\n",
        "resultCrossValidationRFDataset_Satellite,\n",
        "resultCrossValidationRFDataset_AedesSex,\n",
        "resultCrossValidationRFDataset_phoneme,\n",
        "resultCrossValidationRFDataset_adult,\n",
        "resultCrossValidationRFDataset_airlines,\n",
        "resultCrossValidationRFDataset_arrhythmia)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Os algoritmos para PhishingWebsites são muito parecidos ou iguais.\n",
            "0.02534940552272465\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import friedmanchisquare\n",
        "\n",
        "\n",
        "if friedmanchisquare(resultCrossValidationTreeDecisionDataset_PhishingWebsites,resultCrossValidationRFDataset_PhishingWebsites,resultCrossValidationKnnDataset_PhishingWebsites)[1] > 0.05:\n",
        "  print(\"Os algoritmos para PhishingWebsites são muito parecidos ou iguais.\")\n",
        "\n",
        "if friedmanchisquare(resultCrossValidationTreeDecisionDataset_Satellite,resultCrossValidationRFDataset_Satellite,resultCrossValidationKnnDataset_Satellite)[1] > 0.05:\n",
        "  print(\"Os algoritmos para Satellite são muito parecidos ou iguais.\")\n",
        "\n",
        "if friedmanchisquare(resultCrossValidationTreeDecisionDataset_AedesSex,resultCrossValidationRFDataset_AedesSex,resultCrossValidationKnnDataset_AedesSex)[1] > 0.05:\n",
        "  print(\"Os algoritmos para AedesSex são muito parecidos ou iguais.\")\n",
        "\n",
        "if friedmanchisquare(resultCrossValidationTreeDecisionDataset_phoneme,resultCrossValidationRFDataset_phoneme,resultCrossValidationKnnDataset_phoneme)[1] > 0.05:\n",
        "  print(\"Os algoritmos para phoneme são muito parecidos ou iguais.\")\n",
        "\n",
        "if friedmanchisquare(resultCrossValidationTreeDecisionDataset_adult,resultCrossValidationRFDataset_adult,resultCrossValidationKnnDataset_adult)[1] > 0.05:\n",
        "  print(\"Os algoritmos para adult são muito parecidos ou iguais.\")\n",
        "\n",
        "if friedmanchisquare(resultCrossValidationTreeDecisionDataset_airlines,resultCrossValidationRFDataset_airlines,resultCrossValidationKnnDataset_airlines)[1] > 0.05:\n",
        "  print(\"Os algoritmos para airlines são muito parecidos ou iguais.\")\n",
        "\n",
        "if friedmanchisquare(resultCrossValidationTreeDecisionDataset_arrhythmia,resultCrossValidationRFDataset_arrhythmia,resultCrossValidationKnnDataset_arrhythmia)[1] > 0.05:\n",
        "  print(\"Os algoritmos para arrhythmia são muito parecidos ou iguais.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Trabalho_1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
